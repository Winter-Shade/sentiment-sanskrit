{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       text_sanskrit  \\\n",
      "0                     भवान् सायङ्काले किं करिष्यति ?   \n",
      "1                                                      \n",
      "2  Balance Sheet  मध्ये रिफ़्लेक्षन् दृष्टुम् अपि...   \n",
      "3  \"\"\"मनुष्यपुत्रेणावश्यं बहवो यातना भोक्तव्याः प...   \n",
      "4                                                      \n",
      "\n",
      "                                        text_english  label  split  \n",
      "0                   What will you do in the evening?      1  train  \n",
      "1  Some have praised _Atlantis:_The_Lost_Empire_ ...      0  train  \n",
      "2  See the reflection in Balance Sheet and  Void ...      1  train  \n",
      "3  \"\"\"And he began to teach them, that the Son of...      0  train  \n",
      "4  I think Cliff Robertson certainly was one of o...      0  train  \n",
      "(37500, 4)\n",
      "label\n",
      "1    12500\n",
      "0    12500\n",
      "2    12500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"data/processed/final_clsa_dataset.parquet\"\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (30000, 4)\n",
      "Val: (3750, 4)\n",
      "Test: (3750, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.20, stratify=df[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, stratify=temp_df[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Val:\", val_df.shape)\n",
    "print(\"Test:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "encoder = SentenceTransformer(model_name)\n",
    "\n",
    "print(\"Embedding dimension:\", encoder.get_sentence_embedding_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bfa605f83a413aaee06ecfbb8495dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0032377dd74314b3ddab9b116730e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10772665cc1d416399c849f2d6f8b6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings: (30000, 384)\n",
      "Validation embeddings: (3750, 384)\n",
      "Test embeddings: (3750, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def embed(texts):\n",
    "    return encoder.encode(\n",
    "        list(texts),\n",
    "        batch_size=64,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "X_train = embed(train_df[\"text_sanskrit\"])\n",
    "y_train = train_df[\"label\"].values\n",
    "\n",
    "X_val = embed(val_df[\"text_sanskrit\"])\n",
    "y_val = val_df[\"label\"].values\n",
    "\n",
    "X_test = embed(test_df[\"text_sanskrit\"])\n",
    "y_test = test_df[\"label\"].values\n",
    "\n",
    "print(\"Train embeddings:\", X_train.shape)\n",
    "print(\"Validation embeddings:\", X_val.shape)\n",
    "print(\"Test embeddings:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (48726362.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[23], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(...):\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(...):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = EmbeddingDataset(X_train, y_train)\n",
    "val_dataset   = EmbeddingDataset(X_val, y_val)\n",
    "test_dataset  = EmbeddingDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_dim = X_train.shape[1]  # 384 for MiniLM\n",
    "model = MLPClassifier(input_dim=input_dim, hidden_dim=256, dropout=0.3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 0.6963\n",
      "Epoch 2/30 - Loss: 0.6538\n",
      "Epoch 3/30 - Loss: 0.6455\n",
      "Epoch 4/30 - Loss: 0.6392\n",
      "Epoch 5/30 - Loss: 0.6330\n",
      "Epoch 6/30 - Loss: 0.6269\n",
      "Epoch 7/30 - Loss: 0.6215\n",
      "Epoch 8/30 - Loss: 0.6143\n",
      "Epoch 9/30 - Loss: 0.6092\n",
      "Epoch 10/30 - Loss: 0.6018\n",
      "Epoch 11/30 - Loss: 0.5950\n",
      "Epoch 12/30 - Loss: 0.5910\n",
      "Epoch 13/30 - Loss: 0.5805\n",
      "Epoch 14/30 - Loss: 0.5788\n",
      "Epoch 15/30 - Loss: 0.5721\n",
      "Epoch 16/30 - Loss: 0.5679\n",
      "Epoch 17/30 - Loss: 0.5590\n",
      "Epoch 18/30 - Loss: 0.5561\n",
      "Epoch 19/30 - Loss: 0.5544\n",
      "Epoch 20/30 - Loss: 0.5481\n",
      "Epoch 21/30 - Loss: 0.5463\n",
      "Epoch 22/30 - Loss: 0.5387\n",
      "Epoch 23/30 - Loss: 0.5365\n",
      "Epoch 24/30 - Loss: 0.5333\n",
      "Epoch 25/30 - Loss: 0.5282\n",
      "Epoch 26/30 - Loss: 0.5285\n",
      "Epoch 27/30 - Loss: 0.5250\n",
      "Epoch 28/30 - Loss: 0.5225\n",
      "Epoch 29/30 - Loss: 0.5183\n",
      "Epoch 30/30 - Loss: 0.5146\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION:\n",
      "Accuracy: 0.6381333333333333\n",
      "F1 Macro: 0.5787323145577227\n",
      "\n",
      "TEST:\n",
      "Accuracy: 0.6432\n",
      "F1 Macro: 0.586334399898973\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.90      0.67      1250\n",
      "           1       0.79      0.88      0.83      1250\n",
      "           2       0.65      0.15      0.25      1250\n",
      "\n",
      "    accuracy                           0.64      3750\n",
      "   macro avg       0.66      0.64      0.59      3750\n",
      "weighted avg       0.66      0.64      0.59      3750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            batch_pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            preds.extend(batch_pred)\n",
    "            labels.extend(y_batch.numpy())\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return acc, f1, labels, preds\n",
    "\n",
    "val_acc, val_f1, _, _   = evaluate(val_loader)\n",
    "test_acc, test_f1, yt, yp = evaluate(test_loader)\n",
    "\n",
    "print(\"VALIDATION:\")\n",
    "print(\"Accuracy:\", val_acc)\n",
    "print(\"F1 Macro:\", val_f1)\n",
    "\n",
    "print(\"\\nTEST:\")\n",
    "print(\"Accuracy:\", test_acc)\n",
    "print(\"F1 Macro:\", test_f1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(yt, yp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
